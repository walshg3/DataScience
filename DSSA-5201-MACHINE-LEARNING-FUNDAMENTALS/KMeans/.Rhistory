wss = vector(mode = "numeric", length = length(ks))
#k=3 # the number of K
max=5000 # the maximumm number for generating randome points
n=100 # the number of points
maxIter = 10 # maximum number of iterations
threshold = 0.1 #difference of old means and new means
# Randomly generate points in the form of (x,y)
x <- sample(1:max, n)
y <- sample(1:max, n)
# put point into a matrix
z <- c(x,y)
m = matrix(z, ncol=2)
ks <- c(1,2,4,8,10,15,20) # different Ks
for(k in ks)
myKmeans(m, k, max)
myKmeans <- function(m, k, max)
{
#initialization for k means: the k-first points in the list
x <- m[, 1]
y <- m[, 2]
d=matrix(data=NA, ncol=0, nrow=0)
for(i in 1:k)
d <-  c(d, c(x[i], y[i]))
init <- matrix(d, ncol=2, byrow=TRUE)
dev.new()
plotTitle <- paste("K-Means Clustering [Mehdi Mohammadi] K = ", k)
plot(m, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y", pch=20,
main=plotTitle)
par(new=T)
plot(init, pch=2, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
oldMeans <- init
oldMeans
cl <- Clustering(m, oldMeans)
cl
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- 1
while(thr > threshold)
{
cl <- Clustering(m, means)
oldMeans <- means
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- itr+1
}
cl
thr
means
itr
for(km in 1:k)
{
group <- which(cl == km)
plot(m[group,],axes=F, col=km, xlim=c(1,max), ylim=c(1,max), pch=20, xlab="X", ylab="Y")
par(new=T)
}
plot(means, axes=F, pch=8, col=15, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
dev.off()
}
#function distance
dist <- function(x,y)
{
d<-sqrt( sum((x - y) **2 ))
}
createMeanMatrix <- function(d)
{
matrix(d, ncol=2, byrow=TRUE)
}
# compute euclidean distance
euclid <- function(a,b){
d<-sqrt(a**2 + b**2)
}
euclid2 <- function(a){
d<-sqrt(sum(a**2))
}
#compute difference between new means and old means
delta <- function(oldMeans, newMeans)
{
a <- newMeans - oldMeans
max(euclid(a[, 1], a[, 2]))
}
Clustering <- function(m, means)
{
clusters = c()
n <- nrow(m)
for(i in 1:n)
{
distances = c()
k <- nrow(means)
for(j in 1:k)
{
di <- m[i,] - means[j,]
ds<-euclid2(di)
distances <- c(distances, ds)
}
minDist <- min(distances)
cl <- match(minDist, distances)
clusters <- c(clusters, cl)
}
return (clusters)
}
UpdateMeans <- function(m, cl, k)
{
means <- c()
for(c in 1:k)
{
# get the point of cluster c
group <- which(cl == c)
# compute the mean point of all points in cluster c
mt1 <- mean(m[group,1])
mt2 <- mean(m[group,2])
vMean <- c(mt1, mt2)
means <- c(means, vMean)
}
means <- createMeanMatrix(means)
return(means)
}
myKmeans <- function(m, k, max)
{
#initialization for k means: the k-first points in the list
x <- m[, 1]
y <- m[, 2]
d=matrix(data=NA, ncol=0, nrow=0)
for(i in 1:k)
d <-  c(d, c(x[i], y[i]))
init <- matrix(d, ncol=2, byrow=TRUE)
dev.new()
plotTitle <- paste("K-Means Clustering [Mehdi Mohammadi] K = ", k)
plot(m, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y", pch=20,
main=plotTitle)
par(new=T)
plot(init, pch=2, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
oldMeans <- init
oldMeans
cl <- Clustering(m, oldMeans)
cl
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- 1
while(thr > threshold)
{
cl <- Clustering(m, means)
oldMeans <- means
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- itr+1
}
cl
thr
means
itr
for(km in 1:k)
{
group <- which(cl == km)
plot(m[group,],axes=F, col=km, xlim=c(1,max), ylim=c(1,max), pch=20, xlab="X", ylab="Y")
par(new=T)
}
plot(means, axes=F, pch=8, col=15, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
dev.off()
}
ks <- c(1,2,4,8,10,15,20) # different Ks
for(k in ks)
myKmeans(m, k, max)
View(myKmeans)
myKmeans <- function(m, k, max)
{
#initialization for k means: the k-first points in the list
x <- m[, 1]
y <- m[, 2]
d=matrix(data=NA, ncol=0, nrow=0)
for(i in 1:k)
d <-  c(d, c(x[i], y[i]))
init <- matrix(d, ncol=2, byrow=TRUE)
dev.new()
plotTitle <- paste("K-Means Clustering [Mehdi Mohammadi] K = ", k)
plot(m, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y", pch=20,
main=plotTitle)
par(new=T)
plot(init, pch=2, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
oldMeans <- init
oldMeans
cl <- Clustering(m, oldMeans)
cl
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- 1
while(thr > threshold)
{
cl <- Clustering(m, means)
oldMeans <- means
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- itr+1
}
cl
thr
means
itr
for(km in 1:k)
{
group <- which(cl == km)
plot(m[group,],axes=F, col=km, xlim=c(1,max), ylim=c(1,max), pch=20, xlab="X", ylab="Y")
par(new=T)
}
plot(means, axes=F, pch=8, col=15, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
dev.off()
}
#function distance
dist <- function(x,y)
{
d<-sqrt( sum((x - y) **2 ))
}
createMeanMatrix <- function(d)
{
matrix(d, ncol=2, byrow=TRUE)
}
# compute euclidean distance
euclid <- function(a,b){
d<-sqrt(a**2 + b**2)
}
euclid2 <- function(a){
d<-sqrt(sum(a**2))
}
#compute difference between new means and old means
delta <- function(oldMeans, newMeans)
{
a <- newMeans - oldMeans
max(euclid(a[, 1], a[, 2]))
}
Clustering <- function(m, means)
{
clusters = c()
n <- nrow(m)
for(i in 1:n)
{
distances = c()
k <- nrow(means)
for(j in 1:k)
{
di <- m[i,] - means[j,]
ds<-euclid2(di)
distances <- c(distances, ds)
}
minDist <- min(distances)
cl <- match(minDist, distances)
clusters <- c(clusters, cl)
}
return (clusters)
}
UpdateMeans <- function(m, cl, k)
{
means <- c()
for(c in 1:k)
{
# get the point of cluster c
group <- which(cl == c)
# compute the mean point of all points in cluster c
mt1 <- mean(m[group,1])
mt2 <- mean(m[group,2])
vMean <- c(mt1, mt2)
means <- c(means, vMean)
}
means <- createMeanMatrix(means)
return(means)
}
#k=3 # the number of K
max=5000 # the maximumm number for generating randome points
n=100 # the number of points
maxIter = 10 # maximum number of iterations
threshold = 0.1 #difference of old means and new means
x
x
x
#k=3 # the number of K
max=5000 # the maximumm number for generating randome points
n=100 # the number of points
maxIter = 10 # maximum number of iterations
threshold = 0.1 #difference of old means and new means
# Randomly generate points in the form of (x,y)
x <- sample(1:max, n)
y <- sample(1:max, n)
# put point into a matrix
z <- c(x,y)
m = matrix(z, ncol=2)
myKmeans <- function(m, k, max)
{
#initialization for k means: the k-first points in the list
x <- m[, 1]
y <- m[, 2]
d=matrix(data=NA, ncol=0, nrow=0)
for(i in 1:k)
d <-  c(d, c(x[i], y[i]))
init <- matrix(d, ncol=2, byrow=TRUE)
dev.new()
plotTitle <- paste("K-Means Clustering [Mehdi Mohammadi] K = ", k)
plot(m, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y", pch=20,
main=plotTitle)
par(new=T)
plot(init, pch=2, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
oldMeans <- init
oldMeans
cl <- Clustering(m, oldMeans)
cl
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- 1
while(thr > threshold)
{
cl <- Clustering(m, means)
oldMeans <- means
means <- UpdateMeans(m, cl, k)
thr <- delta(oldMeans, means)
itr <- itr+1
}
cl
thr
means
itr
for(km in 1:k)
{
group <- which(cl == km)
plot(m[group,],axes=F, col=km, xlim=c(1,max), ylim=c(1,max), pch=20, xlab="X", ylab="Y")
par(new=T)
}
plot(means, axes=F, pch=8, col=15, xlim=c(1,max), ylim=c(1,max), xlab="X", ylab="Y")
par(new=T)
dev.off()
}
#function distance
dist <- function(x,y)
{
d<-sqrt( sum((x - y) **2 ))
}
createMeanMatrix <- function(d)
{
matrix(d, ncol=2, byrow=TRUE)
}
# compute euclidean distance
euclid <- function(a,b){
d<-sqrt(a**2 + b**2)
}
euclid2 <- function(a){
d<-sqrt(sum(a**2))
}
#compute difference between new means and old means
delta <- function(oldMeans, newMeans)
{
a <- newMeans - oldMeans
max(euclid(a[, 1], a[, 2]))
}
Clustering <- function(m, means)
{
clusters = c()
n <- nrow(m)
for(i in 1:n)
{
distances = c()
k <- nrow(means)
for(j in 1:k)
{
di <- m[i,] - means[j,]
ds<-euclid2(di)
distances <- c(distances, ds)
}
minDist <- min(distances)
cl <- match(minDist, distances)
clusters <- c(clusters, cl)
}
return (clusters)
}
UpdateMeans <- function(m, cl, k)
{
means <- c()
for(c in 1:k)
{
# get the point of cluster c
group <- which(cl == c)
# compute the mean point of all points in cluster c
mt1 <- mean(m[group,1])
mt2 <- mean(m[group,2])
vMean <- c(mt1, mt2)
means <- c(means, vMean)
}
means <- createMeanMatrix(means)
return(means)
}
for(k in ks)
myKmeans(m, k, max)
ks <- c(1,2,4,8,10,15,20) # different Ks
for(k in ks)
myKmeans(m, k, max)
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
KMeansData_Group1[,]
KMeansData_Group1[1,]
len(KMeansData_Group1[1,])
KMeansData_Group1[1,]...length()
KMeansData_Group1[1,].length()
length(KMeansData_Group1[1,])
length(KMeansData_Group1[,1])
length(KMeansData_Group1[, 1])
length(KMeansData_Group1[,])
KMeansData_Group1[,]
length(KMeansData_Group1)
length(KMeansData_Group1[])
length(KMeansData_Group1[,])
length(KMeansData_Group1[1,])
length(KMeansData_Group1[1,2])
length(KMeansData_Group1[1,3])
length(KMeansData_Group1[,1])
length(KMeansData_Group1[,])
length(KMeansData_Group1[,c])
length(KMeansData_Group1[,c(1)])
nrow(KMeansData_Group1)
K_means <- function(x, centers, distFun, nItter) {
clusterHistory <- vector(nItter, mode="list")
centerHistory <- vector(nItter, mode="list")
for(i in 1:nItter) {
distsToCenters <- distFun(x, centers)
clusters <- apply(distsToCenters, 1, which.min)
centers <- apply(x, 2, tapply, clusters, mean)
# Saving history
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
list(clusters=clusterHistory, centers=centerHistory)
}
ktest=as.matrix(KMeansData_Group1)
View(ktest)
centers <- ktest[sample(nrow(ktest), 5),]
View(ktest)
View(centers)
res <- K_means(ktest, centers, euclid, 10)
euclid <- function(points1, points2) {
distanceMatrix <- matrix(NA, nrow=dim(points1)[1], ncol=dim(points2)[1])
for(i in 1:nrow(points2)) {
distanceMatrix[,i] <- sqrt(rowSums(t(t(points1)-points2[i,])^2))
}
distanceMatrix
}
res <- K_means(ktest, centers, euclid, 10)
View(res)
plot(res$clusters, res$centers, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares",
main="The Elbow Curve of Clusters for Fish",
pch=20, cex=2)
plot(res$clusters, res$centers)
plot(res$clusters)
res$clusters
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
plot(res$clusters, length(res$clusters))
length(res$clusters)
res$clusters
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
plot(length(res$clusters), res$clusters)
KMeansData_Group1[1:2]
KMeansData_Group1[0:1]
KMeansData_Group1[1:2]
View(KMeansData_Group1)
distance <- (KMeansData_Group1[1:2])
distance
View(distance)
distance <- (KMeansData_Group1[1])
View(distance)
## Import Data
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
distance <- dist(KMeansData_Group1[1], KMeansData_Group1[2])
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
## Import Data
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
distance <- dist(KMeansData_Group1[1:2])
distance
View(KMeansData_Group1)
summary(distance)
print(distance, digits=3)
print(distance, digits=5)
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
## Import Data
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
distance <- dist(KMeansData_Group1)
print(distance, digits=5)
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
hc.l <- hcl(distance)
plot(hc.l)
## Import Data
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
distance <- dist(KMeansData_Group1[1:2])
hc.l <- hcl(distance)
plot(hc.l)
KMeansData_Group1[sample.int(nrow(KMeansData_Group1), k), ]
## Import Data
KMeansData_Group1 <- read_csv("KMeansData_Group1.csv")
t
View(KMeansData_Group1)
centroids = KMeansData_Group1[sample.int(nrow(KMeansData_Group1), k), ]
centroids = KMeansData_Group1[sample.int(nrow(KMeansData_Group1), 5), ]
View(centroids)
View(KMeansData_Group1)
View(centroids)
View(KMeansData_Group1)
View(centroids)
View(KMeansData_Group1)
source('~/Github/DataScience/DSSA-5201-MACHINE-LEARNING-FUNDAMENTALS/KMeans/Greg_Walsh_KMeans.R')
