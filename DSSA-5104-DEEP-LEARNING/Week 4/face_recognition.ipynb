{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "# Load an images with faces (use your own filename)\n",
    "\n",
    "group = face_recognition.load_image_file(\"groupphoto.jpg\")\n",
    "\n",
    "print(type(group))\n",
    "\n",
    "# Find the pixel locations that bound the faces (top,bottom,right,left)\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(type(face_locations))\n",
    "\n",
    "# Loop through all faces found and create images of just that face\n",
    "\n",
    "for i in face_locations:\n",
    "    top = i[0]\n",
    "    right = i[1] \n",
    "    bottom = i[2] \n",
    "    left = i[3]\n",
    "    face_image = group[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'chin': [(18, 22), (18, 26), (19, 29), (20, 33), (21, 36), (24, 38), (27, 40), (30, 41), (33, 41), (36, 41), (39, 39), (41, 37), (42, 35), (43, 32), (43, 29), (44, 26), (44, 22)], 'left_eyebrow': [(22, 19), (24, 17), (27, 17), (30, 17), (32, 17)], 'right_eyebrow': [(36, 17), (38, 17), (40, 17), (42, 18), (42, 19)], 'nose_bridge': [(34, 19), (34, 21), (34, 24), (34, 26)], 'nose_tip': [(31, 28), (33, 28), (34, 29), (35, 28), (36, 28)], 'left_eye': [(25, 21), (26, 20), (28, 20), (29, 20), (28, 21), (26, 21)], 'right_eye': [(37, 20), (38, 20), (40, 20), (41, 21), (40, 21), (38, 21)], 'top_lip': [(29, 35), (31, 32), (33, 32), (34, 32), (35, 32), (36, 32), (37, 34), (37, 34), (35, 33), (34, 33), (33, 33), (29, 34)], 'bottom_lip': [(37, 34), (36, 35), (35, 35), (34, 35), (32, 35), (31, 35), (29, 35), (29, 34), (33, 34), (34, 34), (35, 33), (37, 34)]}]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "# Find facial features (use your own graphics file)\n",
    "face_to_check = face_recognition.load_image_file(\"DC.png\")\n",
    "\n",
    "# This will return a dictionary where the key is the feature and\n",
    "# the data is a list of tuples with the pixel locations where the \n",
    "# feature is\n",
    "face_landmarks_list = face_recognition.face_landmarks(face_to_check)\n",
    "\n",
    "print(type(face_landmarks_list))\n",
    "\n",
    "print(face_landmarks_list)\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_landmarks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(face_landmarks_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same person =  [True]\n"
     ]
    }
   ],
   "source": [
    "# Compare a face to another known picture of same person\n",
    "\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "# Load image file of known person\n",
    "known_image = face_recognition.load_image_file(\"DC.png\")\n",
    "# Load image file in which you ar elooking for that person\n",
    "unknown_image = face_recognition.load_image_file(\"DC2.png\" )\n",
    "\n",
    "dc_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([dc_encoding], unknown_encoding)\n",
    "\n",
    "pil_image1 = Image.fromarray(known_image)\n",
    "pil_image1.show()\n",
    "\n",
    "pil_image2 = Image.fromarray(unknown_image)\n",
    "pil_image2.show()\n",
    "\n",
    "print('Same person = ', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
